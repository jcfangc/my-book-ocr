import json
from datetime import datetime
from pathlib import Path

from loguru import logger

from src.definition.const.core import CLIENT
from src.definition.const.location import OUTPUT_DIR
from src.pipeline.task.openai_batch import download_batch_output


def list_recent_batches(limit: int = 10):
    """
    åˆ—å‡ºæœ€è¿‘çš„ batch æ‰¹å¤„ç†ä»»åŠ¡ä¿¡æ¯ã€‚
    """
    batches = CLIENT.batches.list(limit=limit)
    for batch in batches.data:
        created = datetime.fromtimestamp(batch.created_at).strftime("%Y-%m-%d %H:%M:%S")
        logger.info(
            f"ğŸ†” batch_id: {batch.id} | çŠ¶æ€: {batch.status} | åˆ›å»ºæ—¶é—´: {created} | è¯·æ±‚æ•°: {batch.request_counts.total}"
        )


def fetch_output_from_existing_batch(
    batch_id: str, save_path: Path = OUTPUT_DIR / "ocr.jsonl"
) -> None:
    """
    ä½¿ç”¨ batch_id è·å–å·²å®Œæˆæ‰¹æ¬¡çš„è¾“å‡ºæ–‡ä»¶ï¼Œå¹¶ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„ã€‚
    """
    batch = CLIENT.batches.retrieve(batch_id)
    if batch.status != "completed":
        raise RuntimeError(
            f"æ‰¹æ¬¡çŠ¶æ€å°šæœªå®Œæˆï¼ˆå½“å‰çŠ¶æ€: {batch.status}ï¼‰ï¼Œæ— æ³•ä¸‹è½½è¾“å‡ºã€‚"
        )
    output_file_id = batch.output_file_id
    download_batch_output(output_file_id, save_path)


def decode_openai_jsonl(input_path: Path, output_path: Path) -> None:
    """
    å°† OpenAI Batch JSONL è¾“å‡ºæ–‡ä»¶è½¬æ¢ä¸ºçº¯æ–‡æœ¬ Markdownã€‚
    """

    if not input_path.exists():
        raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ {input_path} ä¸å­˜åœ¨ã€‚")
    if not input_path.is_file():
        raise ValueError(f"è¾“å…¥è·¯å¾„ {input_path} ä¸æ˜¯ä¸€ä¸ªæ–‡ä»¶ã€‚")
    if output_path.exists() and not output_path.is_file():
        raise ValueError(f"è¾“å‡ºè·¯å¾„ {output_path} ä¸æ˜¯ä¸€ä¸ªæ–‡ä»¶ã€‚")
    if output_path.exists():
        logger.warning(f"è¾“å‡ºæ–‡ä»¶ {output_path} å·²å­˜åœ¨ï¼Œå°†è¢«è¦†ç›–ã€‚")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_path.parent.mkdir(parents=True, exist_ok=True)

    with input_path.open("r", encoding="utf-8") as f_in, output_path.open(
        "w", encoding="utf-8"
    ) as f_out:
        for line in f_in:
            record: dict = json.loads(line)  # è‡ªåŠ¨å¤„ç†è½¬ä¹‰
            custom_id = record.get("custom_id", "unknown")

            text_blocks = []
            for message in record.get("response", {}).get("body", {}).get("output", []):
                if message.get("type") == "message":
                    for chunk in message.get("content", []):
                        if chunk.get("type") == "output_text":
                            text_blocks.append(chunk.get("text", ""))
            markdown_text = "\n".join(text_blocks)

            f_out.write(f"<!-- {custom_id} -->\n")
            f_out.write(markdown_text + "\n\n")

    print(f"âœ… å·²ä¿å­˜ Markdown æ–‡æœ¬è‡³ {output_path}")


if __name__ == "__main__":
    # # ç¤ºä¾‹ï¼šåˆ—å‡ºæœ€è¿‘çš„ 5 ä¸ªæ‰¹å¤„ç†ä»»åŠ¡
    # list_recent_batches(limit=5)

    # # ç¤ºä¾‹ï¼šä¸‹è½½æŒ‡å®š batch_id çš„è¾“å‡ºæ–‡ä»¶
    # batch_id = "batch_67f1a3b93b588190809e50f5a4910ef9"

    # fetch_output_from_existing_batch(batch_id)
    # ç¤ºä¾‹ï¼šå°† OpenAI Batch JSONL è¾“å‡ºè½¬æ¢ä¸º Markdown æ–‡æœ¬
    input_path = OUTPUT_DIR / "ocr.jsonl"
    output_path = OUTPUT_DIR / "ocr.md"
    decode_openai_jsonl(input_path, output_path)
